{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for processing raw data files after fetching from source\n",
    "# Preprocess is performed for all data files in the directory, regardless of the CLASS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FOR ACADEMIC PROJECT WORK\n",
    "#check if lib install or not, if not, install\n",
    "# pip install torch\n",
    "# pip install wfdb\n",
    "# pip install shap\n",
    "# pip install biosppy\n",
    "# pip install PyWavelets\n",
    "# pip install pandas\n",
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import wfdb\n",
    "#key parameters:\n",
    "split_type = os.path.sep #newly added. Long. 23.Mar.24\n",
    "dx_dict = {\n",
    "    '426783006': 'SNR', # Normal sinus rhythm\n",
    "    '164889003': 'AF', # Atrial fibrillation\n",
    "    '270492004': 'IAVB', # First-degree atrioventricular block\n",
    "    '164909002': 'LBBB', # Left bundle branch block\n",
    "    '713427006': 'RBBB', # Complete right bundle branch block\n",
    "    '59118001': 'RBBB', # Right bundle branch block\n",
    "    '284470004': 'PAC', # Premature atrial contraction\n",
    "    '63593006': 'PAC', # Supraventricular premature beats\n",
    "    '164884008': 'PVC', # Ventricular ectopics\n",
    "    '429622005': 'STD', # ST-segment depression\n",
    "    '164931005': 'STE', # ST-segment elevation\n",
    "}\n",
    "classes = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. FUNCTION READ, AND MODIFY FILES\n",
    "#Read data from each INDIVIDUAL file, modify it in the right format\n",
    "# and save it back\n",
    "\n",
    "def process_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        main_content = file.read()\n",
    "    # main_content = re.search(r'<code>(.*?)</code>', main_content, re.DOTALL) #no need to get part of the file\n",
    "    file.close()\n",
    "    if main_content:\n",
    "        # lines = main_content.group(1).split('\\n')\n",
    "        lines = main_content.split('\\n')\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "        lines[0] = lines[0] + ' ' + dt_string #append date time to first line\n",
    "        for i in range(1, 13):\n",
    "            #get location of '.mat' in the line\n",
    "            mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n",
    "            # print(mat_loc)\n",
    "            lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1'\n",
    "            lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)'\n",
    "        for i in range(13, len(lines)):\n",
    "            lines[i] = lines[i].replace('# ', '#') #replace \"#\" with \"# \" in the remaining lines\n",
    "        new_content = '\\n'.join(lines)\n",
    "        # new_file_name = file_name.replace('.hea', '_new.hea') #no need to change the file name\n",
    "        #overwrite the original file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(new_content)\n",
    "            file.close()\n",
    "        # print('New file created:', file_name)\n",
    "    else:\n",
    "        print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. FUNCTION MOVE FILES\n",
    "#Within a folder, move all files to from subfolders to main folder\n",
    "def copy_files(folder, N):\n",
    "    files = os.listdir(folder)\n",
    "    #if N = 0, loop all files\n",
    "    if N == 0:\n",
    "        N = len(files)\n",
    "\n",
    "    for i in range(N):\n",
    "        file_name = os.path.join(folder, files[i])\n",
    "        new_folder = os.path.dirname(folder) #copy to upper folder\n",
    "        # new_folder = os.path.join(os.path.dirname(folder), 'main-data')\n",
    "        shutil.copy(file_name, new_folder)\n",
    "        # print('Copied:', file_name)\n",
    "    print('Done, ', N, 'files copied in', folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. FUNCTION MOVE AND PROCESS FILES\n",
    "# Call copy_files to move files from subfolders to main folder\n",
    "# Call process_file to make necessary changes for each files in the main folder\n",
    "#Modification is done for all files, regardless of the class\n",
    "\n",
    "def main_raw_files_process(data_folder, N):\n",
    "    #STEP 1: Copy N files from each sub-folder to main folder\n",
    "\n",
    "    #make a list of sub-folders within the main data folder\n",
    "    folders = os.listdir(data_folder)\n",
    "    #loop through the folders and copy N files from each sub-folder\n",
    "    for folder in folders:\n",
    "        folder_name = os.path.join(data_folder, folder)\n",
    "        if os.path.isdir(folder_name): #filter dirs only\n",
    "            copy_files(folder_name, N)\n",
    "    print('Done copying files from subfolders to main folder:', data_folder)\n",
    "\n",
    "    #STEP 2: Process each file in the main folder\n",
    "    #loop through the files in main folder and process each file\n",
    "    files = os.listdir(data_folder)\n",
    "    #make full path to each file\n",
    "    files = [os.path.join(data_folder, file) for file in files]\n",
    "    for file in files:\n",
    "        if file.endswith('.hea'):\n",
    "            process_file(file)\n",
    "    print('Done processing folders:', data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. function to move files .hea and .mat from one folder to another.\n",
    "#Files name are extracted from 1st column of df\n",
    "\n",
    "def move_files(df, source_folder, dest_folder):\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row['File']\n",
    "        #append '.hea' and '.mat' to the file name, and move the files, one by one\n",
    "        for ext in ['.hea', '.mat']:\n",
    "            source_file = os.path.join(source_folder, file_name + ext)\n",
    "            dest_file = os.path.join(dest_folder, file_name + ext)\n",
    "            shutil.move(source_file, dest_file)\n",
    "    print('Done moving files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Move files to corresponding folders based on the class\n",
    "def conditional_move(data_dir,des_dir,split_type,dx_dict,classes):\n",
    "    #phase 1: read and create labels for each class\n",
    "    recordpaths = glob(os.path.join(data_dir, '*.hea'))\n",
    "    results = []\n",
    "    for recordpath in recordpaths:\n",
    "        patient_id = recordpath.split(split_type)[-1][:-4]\n",
    "        _, meta_data = wfdb.rdsamp(recordpath[:-4]) \n",
    "        dx = meta_data['comments'][2]\n",
    "        dx = dx[4:] if dx.startswith('Dx: ') else ''\n",
    "        results.append([patient_id, dx])\n",
    "    df = pd.DataFrame(data=results, columns=['patient_id', 'dx'])\n",
    "    # print('Check 1')\n",
    "    # #view df\n",
    "    # print(df.head())\n",
    "\n",
    "    #phase 2: create labels for each class\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        patient_id = row['patient_id']\n",
    "        dxs = [dx_dict.get(code, '') for code in row['dx'].split(',')]\n",
    "        # labels = [0] * 9\n",
    "        labels = [0] * len(classes) #Modified to handle additional classes. Long. 21.Apr.24\n",
    "        for idx, label in enumerate(classes):\n",
    "            if label in dxs:\n",
    "                labels[idx] = 1\n",
    "        results.append([patient_id] + labels)\n",
    "    df = pd.DataFrame(data=results, columns=['patient_id'] + classes)\n",
    "    # print('Check 2')\n",
    "    # #view df\n",
    "    # print(df.head())\n",
    "\n",
    "    #only keep records exist in classes list. Long. 05.May.24\n",
    "    df['keep'] = df[classes].sum(axis=1) #sum of all classes\n",
    "    df = df[df['keep'] > 0] #at least one class is 1\n",
    "    \n",
    "    #print number of keep records, number of results, percentage of keep records vs results\n",
    "    print('Number of keep records:', len(df), \n",
    "            '\\nNumber of results:', len(results), \n",
    "            '\\nPercentage of keep records:', len(df)/len(results)*100)       \n",
    "    \n",
    "    #after filtering those keep records,\n",
    "    #move those to new destination folder:\n",
    "    # des_dir = 'data/test_dataset'\n",
    "    if os.path.exists(des_dir):\n",
    "        for index, row in df.iterrows():\n",
    "            file_name = row['patient_id'] #extract file name from 1st column\n",
    "            # print('File name:', file_name)\n",
    "            #append '.hea' and '.mat' to the file name, and move the files, one by one\n",
    "            for ext in ['.hea', '.mat']:\n",
    "                source_file = os.path.join(data_dir, file_name + ext)\n",
    "                dest_file = os.path.join(des_dir, file_name + ext)\n",
    "                shutil.move(source_file, dest_file)\n",
    "            print('Done moving files')\n",
    "    else:\n",
    "        print('Destination folder does not exist:', des_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpsc_2018_extra\n",
    "#modify files from raw downloaded data, select files based on the class, move files to train_dataset or test_dataset\n",
    "source_folder = 'data\\cpsc_2018_extra'\n",
    "des_folder = 'data\\op_09_classes\\\\test_dataset'\n",
    "main_raw_files_process(source_folder, 0)\n",
    "conditional_move(source_folder,des_folder,split_type,dx_dict,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpsc_2018\n",
    "#modify files from raw downloaded data, select files based on the class, move files to train_dataset or test_dataset\n",
    "source_folder = 'data\\cpsc_2018'\n",
    "des_folder = 'data\\op_09_classes\\\\test_dataset'\n",
    "main_raw_files_process(source_folder, 0)\n",
    "conditional_move(source_folder,des_folder,split_type,dx_dict,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptb-xl\n",
    "#modify files from raw downloaded data, select files based on the class, move files to train_dataset or test_dataset\n",
    "source_folder = 'data\\ptb-xl'\n",
    "des_folder = 'data\\op_09_classes\\\\train_dataset'\n",
    "main_raw_files_process(source_folder, 0)\n",
    "conditional_move(source_folder,des_folder,split_type,dx_dict,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping: /scratch/project_2010942/data/op_09_classes.zip\n",
      "Unzipped: /scratch/project_2010942/data/op_09_classes.zip\n",
      "Unzipping: /scratch/project_2010942/data/op_08_classes.zip\n",
      "Unzipped: /scratch/project_2010942/data/op_08_classes.zip\n",
      "Unzipping: /scratch/project_2010942/data/cpsc_processed.zip\n",
      "Unzipped: /scratch/project_2010942/data/cpsc_processed.zip\n",
      "Folder created: /scratch/project_2010942/data/archived\n",
      "Moved: /scratch/project_2010942/data/op_09_classes.zip\n",
      "Moved: /scratch/project_2010942/data/op_08_classes.zip\n",
      "Moved: /scratch/project_2010942/data/cpsc_processed.zip\n"
     ]
    }
   ],
   "source": [
    "#Handle zip files, after uploading from local to codespaces\n",
    "\n",
    "#loop through each zip file in data folder, and unzip it\n",
    "zip_files = glob('/scratch/project_2010942/data/*.zip')\n",
    "for zip_file in zip_files:\n",
    "    print('Unzipping:', zip_file)\n",
    "    shutil.unpack_archive(zip_file, '/scratch/project_2010942/data')\n",
    "    print('Unzipped:', zip_file)\n",
    "    \n",
    "#create folder archived within data folder, and move all zip files to this folder, to backup\n",
    "if not os.path.exists('/scratch/project_2010942/data/archived'):\n",
    "    os.makedirs('/scratch/project_2010942/data/archived')\n",
    "    print('Folder created: /scratch/project_2010942/data/archived')\n",
    "for zip_file in zip_files:\n",
    "    shutil.move(zip_file, '/scratch/project_2010942/data/archived')\n",
    "    print('Moved:', zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify results\n",
    "#check number of files in each subfolder within data folder\n",
    "folders = os.listdir('data')\n",
    "\n",
    "for folder in folders:\n",
    "    #if not folder name archived, then proceed\n",
    "    if folder == 'op_08_classes' or folder == 'op_09_classes':     \n",
    "        folder_name = os.path.join('data', folder)    \n",
    "        subfolders = os.listdir(folder_name)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_name = os.path.join(folder_name, subfolder)    \n",
    "            #print number of files in each subfolder\n",
    "            files = os.listdir(subfolder_name)\n",
    "            print('Number of files in', subfolder_name, ':', len(files))\n",
    "    #else if\n",
    "    elif folder == 'archived' and folder == '.gitkeep':\n",
    "        folder_name = os.path.join('data', folder)    \n",
    "        #print number of files in each subfolder\n",
    "        files = os.listdir(folder_name)\n",
    "        print('Number of files in', folder_name, ':', len(files))   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of classes in each dataset\n",
    "#count number of classes in each dataset\n",
    "def count_classes(label_file, classes):\n",
    "    df = pd.read_csv(label_file)\n",
    "    results = []\n",
    "    for label in classes:\n",
    "        count = df[label].sum()\n",
    "        results.append([label, count])\n",
    "    df = pd.DataFrame(data=results, columns=['Class', 'Count'])\n",
    "    return df\n",
    "\n",
    "#define sequence of classes, and label\n",
    "classes_8 = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'STD', 'STE']\n",
    "classes_9 = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New 8 classes in TEST:\n",
      "          0     1     2     3     4    5    6    7\n",
      "Class   SNR    AF  IAVB  LBBB  RBBB  PAC  STD  STE\n",
      "Count  1826  1780   247   205   454  258  402  176\n",
      "New 9 classes in TEST:\n",
      "         0     1     2     3     4    5    6    7    8\n",
      "Class  SNR    AF  IAVB  LBBB  RBBB  PAC  PVC  STD  STE\n",
      "Count  922  1374   828   274  1971  740  700  926  286\n"
     ]
    }
   ],
   "source": [
    "#Count class distribution in ALL TRAIN dataset:\n",
    "\n",
    "#define label file location for checking string\n",
    "# label_cpsc_8 = 'data/cpsc_processed/labels_8_classes.csv'\n",
    "# label_cpsc_9 = 'data/cpsc_processed/labels_9_classes.csv'\n",
    "# label_new_8 = 'data/op_08_classes/train_dataset/labels_8_classes.csv'\n",
    "# label_new_9 = 'data/op_09_classes/train_dataset/labels_9_classes.csv'\n",
    "label_new_8_test = '/scratch/project_2010942/data/op_08_classes/test_dataset/labels_8_classes.csv'\n",
    "label_new_9_test = '/scratch/project_2010942/data/op_09_classes/test_dataset/labels_9_classes.csv'\n",
    "\n",
    "#count classes in each dataset\n",
    "# df_cpsc_8 = count_classes(label_cpsc_8, classes_8)\n",
    "# df_cpsc_9 = count_classes(label_cpsc_9, classes_9)\n",
    "# df_new_8 = count_classes(label_new_8, classes_8)\n",
    "# df_new_9 = count_classes(label_new_9, classes_9)\n",
    "df_new_8_test = count_classes(label_new_8_test, classes_8)\n",
    "df_new_9_test = count_classes(label_new_9_test, classes_9)\n",
    "\n",
    "#view results\n",
    "# print('CSPC 8 classes:')\n",
    "# print(df_cpsc_8.transpose())\n",
    "# print('CSPC 9 classes:')\n",
    "# print(df_cpsc_9.transpose())\n",
    "# print('New 8 classes:')\n",
    "# print(df_new_8.transpose())\n",
    "# print('New 9 classes:')\n",
    "# print(df_new_9.transpose())\n",
    "print('New 8 classes in TEST:')\n",
    "print(df_new_8_test.transpose())\n",
    "print('New 9 classes in TEST:')\n",
    "print(df_new_9_test.transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New 8 classes in TEST:\n",
      "               0     1     2     3     4    5    6    7\n",
      "Class        SNR    AF  IAVB  LBBB  RBBB  PAC  STD  STE\n",
      "Train       1452  1420   202   164   365  209  322  142\n",
      "Validation   374   360    45    41    89   49   80   34\n",
      "New 9 classes in TEST:\n",
      "              0     1     2     3     4    5    6    7    8\n",
      "Class       SNR    AF  IAVB  LBBB  RBBB  PAC  PVC  STD  STE\n",
      "Train       727  1096   658   223  1613  590  563  724  237\n",
      "Validation  195   278   170    51   358  150  137  202   49\n"
     ]
    }
   ],
   "source": [
    "#define folds used to split train and validation parts\n",
    "train_folds = [1, 2, 3, 5, 6, 8, 9, 10]\n",
    "validations_folds = [4, 7]\n",
    "#count sum of each class in train folds and validation folds of each dataseT\n",
    "def count_classes_folds(label_file, classes, train_folds, validations_folds):\n",
    "    df = pd.read_csv(label_file)\n",
    "    results = []\n",
    "    for label in classes:\n",
    "        count_train = df[df['fold'].isin(train_folds)][label].sum()\n",
    "        count_valid = df[df['fold'].isin(validations_folds)][label].sum()\n",
    "        results.append([label, count_train, count_valid])\n",
    "    df = pd.DataFrame(data=results, columns=['Class', 'Train', 'Validation'])\n",
    "    return df\n",
    "#count classes in each dataset\n",
    "# df_cpsc_8 = count_classes_folds(label_cpsc_8, classes_8, train_folds, validations_folds)\n",
    "# df_cpsc_9 = count_classes_folds(label_cpsc_9, classes_9, train_folds, validations_folds)\n",
    "# df_new_8 = count_classes_folds(label_new_8, classes_8, train_folds, validations_folds)\n",
    "# df_new_9 = count_classes_folds(label_new_9, classes_9, train_folds, validations_folds)\n",
    "df_new_8_test = count_classes_folds(label_new_8_test, classes_8, train_folds, validations_folds)\n",
    "df_new_9_test = count_classes_folds(label_new_9_test, classes_9, train_folds, validations_folds)\n",
    "\n",
    "#view results\n",
    "# print('CSPC 8 classes:')\n",
    "# print(df_cpsc_8.transpose())\n",
    "# print('CSPC 9 classes:')\n",
    "# print(df_cpsc_9.transpose())\n",
    "# print('New 8 classes:')\n",
    "# print(df_new_8.transpose())\n",
    "# print('New 9 classes:')\n",
    "# print(df_new_9.transpose())\n",
    "print('New 8 classes in TEST:')\n",
    "print(df_new_8_test.transpose())\n",
    "print('New 9 classes in TEST:')\n",
    "print(df_new_9_test.transpose())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
