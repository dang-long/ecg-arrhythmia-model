{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for processing raw data files after fetching from source\n",
    "# Preprocess is performed for all data files in the directory, regardless of the CLASS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/users/danglong/.local/lib/python3.9/site-packages', '/usr/lib64/python3.9/site-packages', '/usr/lib/python3.9/site-packages']\n"
     ]
    }
   ],
   "source": [
    "#command to install 'ipykernel' into the Python environment. \n",
    "#'/bin/python3.9 -m pip install ipykernel -U --user --force-reinstall'\n",
    "# !python3 -m ensurepip \n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/scratch/project_2010942/.private_libs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python3.9 --version\n",
    "# !apt-get install python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3.9 cache purge\n",
    "!ls \"/usr/bin/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FOR ACADEMIC PROJECT WORK\n",
    "#check if lib install or not, if not, install\n",
    "# pip3.9  install  --target '/scratch/project_2010942/.private_libs' pandas\n",
    "# pip3.9  install  --target '/scratch/project_2010942/.private_libs' wfdb\n",
    "# pip3.9  install  --target '/scratch/project_2010942/.private_libs' lightgbm\n",
    "# pip3.9  install  --target '/scratch/project_2010942/.private_libs' PyWavelets\n",
    "# pip3.9  install  --target '/scratch/project_2010942/.private_libs' biosppy\n",
    "# pip3.9  install  --target '/scratch/project_2010942/.private_libs' shap\n",
    "# !pip3.9  install  --target '/scratch/project_2010942/.private_libs' torch --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import wfdb\n",
    "#key parameters:\n",
    "split_type = os.path.sep #newly added. Long. 23.Mar.24\n",
    "dx_dict = {\n",
    "    '426783006': 'SNR', # Normal sinus rhythm\n",
    "    '164889003': 'AF', # Atrial fibrillation\n",
    "    '270492004': 'IAVB', # First-degree atrioventricular block\n",
    "    '164909002': 'LBBB', # Left bundle branch block\n",
    "    '713427006': 'RBBB', # Complete right bundle branch block\n",
    "    '59118001': 'RBBB', # Right bundle branch block\n",
    "    '284470004': 'PAC', # Premature atrial contraction\n",
    "    '63593006': 'PAC', # Supraventricular premature beats\n",
    "    '164884008': 'PVC', # Ventricular ectopics\n",
    "    '429622005': 'STD', # ST-segment depression\n",
    "    '164931005': 'STE', # ST-segment elevation\n",
    "}\n",
    "classes = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. FUNCTION READ, AND MODIFY FILES\n",
    "#Read data from each INDIVIDUAL file, modify it in the right format\n",
    "# and save it back\n",
    "\n",
    "def process_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        main_content = file.read()\n",
    "    # main_content = re.search(r'<code>(.*?)</code>', main_content, re.DOTALL) #no need to get part of the file\n",
    "    file.close()\n",
    "    if main_content:\n",
    "        # lines = main_content.group(1).split('\\n')\n",
    "        lines = main_content.split('\\n')\n",
    "        now = datetime.now()\n",
    "        dt_string = now.strftime(\"%d-%b-%Y %H:%M:%S\")\n",
    "        lines[0] = lines[0] + ' ' + dt_string #append date time to first line\n",
    "        for i in range(1, 13):\n",
    "            #get location of '.mat' in the line\n",
    "            mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n",
    "            # print(mat_loc)\n",
    "            lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1'\n",
    "            lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)'\n",
    "        for i in range(13, len(lines)):\n",
    "            lines[i] = lines[i].replace('# ', '#') #replace \"#\" with \"# \" in the remaining lines\n",
    "        new_content = '\\n'.join(lines)\n",
    "        # new_file_name = file_name.replace('.hea', '_new.hea') #no need to change the file name\n",
    "        #overwrite the original file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(new_content)\n",
    "            file.close()\n",
    "        # print('New file created:', file_name)\n",
    "    else:\n",
    "        print('No match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. FUNCTION MOVE FILES\n",
    "#Within a folder, move all files to from subfolders to main folder\n",
    "def copy_files(folder, N):\n",
    "    files = os.listdir(folder)\n",
    "    #if N = 0, loop all files\n",
    "    if N == 0:\n",
    "        N = len(files)\n",
    "\n",
    "    for i in range(N):\n",
    "        file_name = os.path.join(folder, files[i])\n",
    "        new_folder = os.path.dirname(folder) #copy to upper folder\n",
    "        # new_folder = os.path.join(os.path.dirname(folder), 'main-data')\n",
    "        shutil.copy(file_name, new_folder)\n",
    "        # print('Copied:', file_name)\n",
    "    print('Done, ', N, 'files copied in', folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. FUNCTION MOVE AND PROCESS FILES\n",
    "# Call copy_files to move files from subfolders to main folder\n",
    "# Call process_file to make necessary changes for each files in the main folder\n",
    "#Modification is done for all files, regardless of the class\n",
    "\n",
    "def main_raw_files_process(data_folder, N):\n",
    "    #STEP 1: Copy N files from each sub-folder to main folder\n",
    "\n",
    "    #make a list of sub-folders within the main data folder\n",
    "    folders = os.listdir(data_folder)\n",
    "    #loop through the folders and copy N files from each sub-folder\n",
    "    for folder in folders:\n",
    "        folder_name = os.path.join(data_folder, folder)\n",
    "        if os.path.isdir(folder_name): #filter dirs only\n",
    "            copy_files(folder_name, N)\n",
    "    print('Done copying files from subfolders to main folder:', data_folder)\n",
    "\n",
    "    #STEP 2: Process each file in the main folder\n",
    "    #loop through the files in main folder and process each file\n",
    "    files = os.listdir(data_folder)\n",
    "    #make full path to each file\n",
    "    files = [os.path.join(data_folder, file) for file in files]\n",
    "    for file in files:\n",
    "        if file.endswith('.hea'):\n",
    "            process_file(file)\n",
    "    print('Done processing folders:', data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. function to move files .hea and .mat from one folder to another.\n",
    "#Files name are extracted from 1st column of df\n",
    "\n",
    "def move_files(df, source_folder, dest_folder):\n",
    "    for index, row in df.iterrows():\n",
    "        file_name = row['File']\n",
    "        #append '.hea' and '.mat' to the file name, and move the files, one by one\n",
    "        for ext in ['.hea', '.mat']:\n",
    "            source_file = os.path.join(source_folder, file_name + ext)\n",
    "            dest_file = os.path.join(dest_folder, file_name + ext)\n",
    "            shutil.move(source_file, dest_file)\n",
    "    print('Done moving files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Move files to corresponding folders based on the class\n",
    "def conditional_move(data_dir,des_dir,split_type,dx_dict,classes):\n",
    "    #phase 1: read and create labels for each class\n",
    "    recordpaths = glob(os.path.join(data_dir, '*.hea'))\n",
    "    results = []\n",
    "    for recordpath in recordpaths:\n",
    "        patient_id = recordpath.split(split_type)[-1][:-4]\n",
    "        _, meta_data = wfdb.rdsamp(recordpath[:-4]) \n",
    "        dx = meta_data['comments'][2]\n",
    "        dx = dx[4:] if dx.startswith('Dx: ') else ''\n",
    "        results.append([patient_id, dx])\n",
    "    df = pd.DataFrame(data=results, columns=['patient_id', 'dx'])\n",
    "    # print('Check 1')\n",
    "    # #view df\n",
    "    # print(df.head())\n",
    "\n",
    "    #phase 2: create labels for each class\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        patient_id = row['patient_id']\n",
    "        dxs = [dx_dict.get(code, '') for code in row['dx'].split(',')]\n",
    "        # labels = [0] * 9\n",
    "        labels = [0] * len(classes) #Modified to handle additional classes. Long. 21.Apr.24\n",
    "        for idx, label in enumerate(classes):\n",
    "            if label in dxs:\n",
    "                labels[idx] = 1\n",
    "        results.append([patient_id] + labels)\n",
    "    df = pd.DataFrame(data=results, columns=['patient_id'] + classes)\n",
    "    # print('Check 2')\n",
    "    # #view df\n",
    "    # print(df.head())\n",
    "\n",
    "    #only keep records exist in classes list. Long. 05.May.24\n",
    "    df['keep'] = df[classes].sum(axis=1) #sum of all classes\n",
    "    df = df[df['keep'] > 0] #at least one class is 1\n",
    "    \n",
    "    #print number of keep records, number of results, percentage of keep records vs results\n",
    "    print('Number of keep records:', len(df), \n",
    "            '\\nNumber of results:', len(results), \n",
    "            '\\nPercentage of keep records:', len(df)/len(results)*100)       \n",
    "    \n",
    "    #after filtering those keep records,\n",
    "    #move those to new destination folder:\n",
    "    # des_dir = 'data/test_dataset'\n",
    "    if os.path.exists(des_dir):\n",
    "        for index, row in df.iterrows():\n",
    "            file_name = row['patient_id'] #extract file name from 1st column\n",
    "            # print('File name:', file_name)\n",
    "            #append '.hea' and '.mat' to the file name, and move the files, one by one\n",
    "            for ext in ['.hea', '.mat']:\n",
    "                source_file = os.path.join(data_dir, file_name + ext)\n",
    "                dest_file = os.path.join(des_dir, file_name + ext)\n",
    "                shutil.move(source_file, dest_file)\n",
    "            print('Done moving files')\n",
    "    else:\n",
    "        print('Destination folder does not exist:', des_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpsc_2018_extra\n",
    "#modify files from raw downloaded data, select files based on the class, move files to train_dataset or test_dataset\n",
    "source_folder = 'data\\cpsc_2018_extra'\n",
    "des_folder = 'data\\op_09_classes\\\\test_dataset'\n",
    "main_raw_files_process(source_folder, 0)\n",
    "conditional_move(source_folder,des_folder,split_type,dx_dict,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cpsc_2018\n",
    "#modify files from raw downloaded data, select files based on the class, move files to train_dataset or test_dataset\n",
    "source_folder = 'data\\cpsc_2018'\n",
    "des_folder = 'data\\op_09_classes\\\\test_dataset'\n",
    "main_raw_files_process(source_folder, 0)\n",
    "conditional_move(source_folder,des_folder,split_type,dx_dict,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptb-xl\n",
    "#modify files from raw downloaded data, select files based on the class, move files to train_dataset or test_dataset\n",
    "source_folder = 'data\\ptb-xl'\n",
    "des_folder = 'data\\op_09_classes\\\\train_dataset'\n",
    "main_raw_files_process(source_folder, 0)\n",
    "conditional_move(source_folder,des_folder,split_type,dx_dict,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping: /scratch/project_2010942/data/op_09_classes.zip\n",
      "Unzipped: /scratch/project_2010942/data/op_09_classes.zip\n",
      "Unzipping: /scratch/project_2010942/data/op_08_classes.zip\n",
      "Unzipped: /scratch/project_2010942/data/op_08_classes.zip\n",
      "Unzipping: /scratch/project_2010942/data/cpsc_processed.zip\n",
      "Unzipped: /scratch/project_2010942/data/cpsc_processed.zip\n",
      "Folder created: /scratch/project_2010942/data/archived\n",
      "Moved: /scratch/project_2010942/data/op_09_classes.zip\n",
      "Moved: /scratch/project_2010942/data/op_08_classes.zip\n",
      "Moved: /scratch/project_2010942/data/cpsc_processed.zip\n"
     ]
    }
   ],
   "source": [
    "#Handle zip files, after uploading from local to codespaces\n",
    "\n",
    "#loop through each zip file in data folder, and unzip it\n",
    "zip_files = glob('/scratch/project_2010942/data/*.zip')\n",
    "for zip_file in zip_files:\n",
    "    print('Unzipping:', zip_file)\n",
    "    shutil.unpack_archive(zip_file, '/scratch/project_2010942/data')\n",
    "    print('Unzipped:', zip_file)\n",
    "    \n",
    "#create folder archived within data folder, and move all zip files to this folder, to backup\n",
    "if not os.path.exists('/scratch/project_2010942/data/archived'):\n",
    "    os.makedirs('/scratch/project_2010942/data/archived')\n",
    "    print('Folder created: /scratch/project_2010942/data/archived')\n",
    "for zip_file in zip_files:\n",
    "    shutil.move(zip_file, '/scratch/project_2010942/data/archived')\n",
    "    print('Moved:', zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verify results\n",
    "#check number of files in each subfolder within data folder\n",
    "folders = os.listdir('data')\n",
    "\n",
    "for folder in folders:\n",
    "    #if not folder name archived, then proceed\n",
    "    if folder == 'op_08_classes' or folder == 'op_09_classes':     \n",
    "        folder_name = os.path.join('data', folder)    \n",
    "        subfolders = os.listdir(folder_name)\n",
    "        for subfolder in subfolders:\n",
    "            subfolder_name = os.path.join(folder_name, subfolder)    \n",
    "            #print number of files in each subfolder\n",
    "            files = os.listdir(subfolder_name)\n",
    "            print('Number of files in', subfolder_name, ':', len(files))\n",
    "    #else if\n",
    "    elif folder != 'archived' and folder != '.gitkeep':\n",
    "        folder_name = os.path.join('data', folder)    \n",
    "        #print number of files in each subfolder\n",
    "        files = os.listdir(folder_name)\n",
    "        print('Number of files in', folder_name, ':', len(files))   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/688 [00:53<3:23:25, 17.82s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/projappl/project_2010942/ecg-arrhythmia-model/main.py:169\u001b[0m\n\u001b[1;32m    167\u001b[0m         net\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(args\u001b[38;5;241m.\u001b[39mmodel_path, map_location\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m--> 169\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m         evaluate(val_loader, net, args, criterion, device)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/projappl/project_2010942/ecg-arrhythmia-model/main.py:40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader, net, args, criterion, epoch, scheduler, optimizer, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (data, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader)):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# print('Round:', idx, 'Label:', labels, 'Data:', data)\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     data, labels \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)        \n\u001b[0;32m---> 40\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, labels)\n\u001b[1;32m     42\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projappl/project_2010942/ecg-arrhythmia-model/resnet.py:118\u001b[0m, in \u001b[0;36mResNet1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    117\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 118\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    120\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/projappl/project_2010942/ecg-arrhythmia-model/resnet.py:25\u001b[0m, in \u001b[0;36mBasicBlock1d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     residual \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m---> 25\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/project_2010942/.private_libs/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train model, using train data: data/cpsc_processed, with full 09 classes:\n",
    "%run \"main.py\" --data-dir \"/scratch/project_2010942/data/cpsc_processed\" --epochs 3 --num-workers 2 --batch-size 8 --num-classes 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
