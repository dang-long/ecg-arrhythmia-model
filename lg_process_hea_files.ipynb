{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":128979,"status":"ok","timestamp":1719914374127,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"lpahMXFy7rkj","outputId":"e9573654-c472-4004-ab59-b8991549d726"},"outputs":[],"source":["#### FOR ACADEMIC PROJECT WORK\n","#check if lib install or not, if not, install\n","\n","# !pip install wfdb\n","# !pip install lightgbm\n","# !pip install PyWavelets\n","# !pip install biosppy\n","# !pip install torch\n","# !pip install shap"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#unzip the data into the data folder\n","# import zipfile\n","# with zipfile.ZipFile('/workspaces/ecg-arrhythmia-model/data/train_dataset.zip', 'r') as zip_ref:\n","#     zip_ref.extractall('/workspaces/ecg-arrhythmia-model/data/')\n","# import os\n","# #check number of files exist in each data folders\n","# print('Number of files in each folder')\n","# print('cpsc_processed:', len(os.listdir('/workspaces/ecg-arrhythmia-model/data/cpsc_processed')))\n","# print('train_dataset:', len(os.listdir('/workspaces/ecg-arrhythmia-model/data/train_dataset')))\n","# print('test_dataset:', len(os.listdir('/workspaces/ecg-arrhythmia-model/data/test_dataset')))"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6Qq6vcDW7qE2"},"outputs":[],"source":["import re\n","from datetime import datetime\n","import shutil\n","import os\n","from utils import load_dictionary_from_file\n","#load .hea file\n","file_name = 'data\\ptb-xl\\HR00001.hea'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrPV-eoT7qE3"},"outputs":[],"source":["# DEBUG CODE - READ FILES\n","\n","with open(file_name, 'r') as file:\n","    main_content = file.read()\n","# look for contains of the file between tag <code> and </code>\n","# and return the first match\n","# match = re.search(r'<code>(.*?)</code>', html_content, re.DOTALL)\n","if main_content:\n","    print(main_content)\n","else:\n","    print('No match')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpvNDe7Z7qE3"},"outputs":[],"source":["# DEBUG CODE - MODIFY FILES\n","\n","#append date time to first line of match\n","from datetime import datetime\n","now = datetime.now()\n","dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n","# print(dt_string)\n","#split the match into lines\n","lines = main_content.split('\\n')\n","#append date time to first line\n","lines[0] = lines[0] + ' ' + dt_string\n","#in the next 12 lines:\n","\n","for i in range(1, 13):\n","    # lines[i] = lines[i][:12] + lines[i][14:] #remove 'x1' after 12th character\n","    # lines[i] = lines[i][:20] + lines[i][25:] #remove '.0(0)' after 20th character\n","    #get location of '.mat' in the line\n","    mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n","    # print(mat_loc)\n","    lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1'\n","    lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)'\n","\n","#in the remaining lines, replace \"#\" with \"# \"\n","for i in range(13, len(lines)):\n","    lines[i] = lines[i].replace('# ', '#')\n","\n","\n","#join the lines back together\n","new_content = '\\n'.join(lines)\n","print(new_content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uTAJ8Ujv7qE4"},"outputs":[],"source":["#1. FUNCTION READ, AND MODIFY FILES\n","def process_file(file_name):\n","    with open(file_name, 'r') as file:\n","        main_content = file.read()\n","    # main_content = re.search(r'<code>(.*?)</code>', main_content, re.DOTALL) #no need to get part of the file\n","    file.close()\n","    if main_content:\n","        # lines = main_content.group(1).split('\\n')\n","        lines = main_content.split('\\n')\n","        now = datetime.now()\n","        dt_string = now.strftime(\"%d-%b-%Y %H:%M:%S\")\n","        lines[0] = lines[0] + ' ' + dt_string #append date time to first line\n","        for i in range(1, 13):\n","            #get location of '.mat' in the line\n","            mat_loc = lines[i].find('.mat')+4 #location id at beginning of '.mat' -> +4 till the end\n","            # print(mat_loc)\n","            lines[i] = lines[i][:mat_loc+3] + lines[i][mat_loc+5:] #remove 'x1'\n","            lines[i] = lines[i][:mat_loc+11] + lines[i][mat_loc+16:] #remove '.0(0)'\n","        for i in range(13, len(lines)):\n","            lines[i] = lines[i].replace('# ', '#') #replace \"#\" with \"# \" in the remaining lines\n","        new_content = '\\n'.join(lines)\n","        # new_file_name = file_name.replace('.hea', '_new.hea') #no need to change the file name\n","        #overwrite the original file\n","        with open(file_name, 'w') as file:\n","            file.write(new_content)\n","            file.close()\n","        # print('New file created:', file_name)\n","    else:\n","        print('No match')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbZxi-4_7qE4"},"outputs":[],"source":["# CALL manual (read and modify files)\n","#loop through the files in main folder and process each file\n","files = os.listdir('data\\CPSC_2018')\n","#make full path to each file\n","files = [os.path.join('data\\CPSC_2018', file) for file in files]\n","for file in files:\n","    if file.endswith('.hea'):\n","        process_file(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dhYywZz17qE4"},"outputs":[],"source":["#2. FUNCTION MOVE FILES\n","def copy_files(folder, N):\n","    files = os.listdir(folder)\n","    #if N = 0, loop all files\n","    if N == 0:\n","        N = len(files)\n","\n","    for i in range(N):\n","        file_name = os.path.join(folder, files[i])\n","        new_folder = os.path.dirname(folder) #copy to upper folder\n","        # new_folder = os.path.join(os.path.dirname(folder), 'main-data')\n","        shutil.copy(file_name, new_folder)\n","        # print('Copied:', file_name)\n","    print('Done, ', N, 'files copied in', folder)\n","\n","# copy_files('.\\data\\CPSC_2018\\g1', 50)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mllEww2Y7qE4"},"outputs":[],"source":["#3. FUNCTION MOVE AND PROCESS FILES\n","\n","def main_hea_process(data_folder, N):\n","    #make a list of sub-folders within the main data folder\n","    folders = os.listdir(data_folder)\n","    #loop through the folders and copy N files from each sub-folder\n","    for folder in folders:\n","        folder_name = os.path.join(data_folder, folder)\n","        if os.path.isdir(folder_name): #filter dirs only\n","            copy_files(folder_name, N)\n","    #loop through the files in main folder and process each file\n","    files = os.listdir(data_folder)\n","    #make full path to each file\n","    files = [os.path.join(data_folder, file) for file in files]\n","    for file in files:\n","        if file.endswith('.hea'):\n","            process_file(file)\n","    print('Done processing folders:', data_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B-RSU2hU7qE4"},"outputs":[],"source":["#define main data folder string\n","data_folder = 'data\\chapman_shaoxing'\n","# 'data\\ptb-xl'\n","# 'data\\cpsc_2018'\n","# 'data\\cpsc_2018_extra'\n","# 'data\\cpsc_processed'\n","\n","#define samples get from each sub-folder\n","N = 0   #sampling files in each sub-folder.\n","        #Total file = N*number of sub-folder\n","        #N=0, get all files in each sub-folder\n","\n","#process the main data folder\n","main_hea_process(data_folder, N)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YhJ4dQ_7qE4"},"outputs":[],"source":["#Utility function to get unique codes from the files\n","\n","def get_unique_dx_code (data_folder):\n","    files = os.listdir(data_folder)\n","    files = [os.path.join(data_folder, file) for file in files]\n","    list_codes = []\n","    for file in files:\n","        if file.endswith('.hea'):\n","            #read 16th line of the file\n","            with open(file, 'r') as f:\n","                lines = f.readlines()\n","                f.close()\n","            #get the 16th line\n","            line = lines[15]\n","            #get text after '#Dx: '\n","            text = line.split('#Dx: ')[1]\n","            #split the text into list of code, delimited by ','\n","            codes = text.split(',')\n","            #remove leading and trailing white spaces from each code\n","            codes = [code.strip() for code in codes]\n","            #append unique codes to the list\n","            for code in codes:\n","                if code not in list_codes:\n","                    list_codes.append(code)\n","    return list_codes\n","\n","#call the function\n","# data_folder = 'data\\cpsc_2018'\n","list_codes = get_unique_dx_code(data_folder)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9_a_VF_7qE5"},"outputs":[],"source":["import json\n","\n","# Function to load dictionary from file\n","def load_dictionary_from_file(filename):\n","    with open(filename, 'r') as file:\n","        dictionary = json.load(file)\n","    return dictionary\n","\n","# Function to store dictionary to file\n","def store_dictionary_to_file(dictionary, filename):\n","    with open(filename, 'w') as file:\n","        json.dump(dictionary, file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45O7Wmhd7qE5"},"outputs":[],"source":["# location of dx_dict file and class_labels file\n","file_dx_name = 'meta_data\\dx_dict.json'  # File name to store the dictionary dx_dict\n","file_class_name = 'meta_data\\class_labels.txt' # File name to store the class labels\n","\n","# if dx_dict can be loaded from file, then load it, else use default dx_dict\n","if os.path.exists(file_dx_name):\n","    dx_dict = load_dictionary_from_file(file_dx_name)\n","else:\n","    #introduce dx_dict to store the codes\n","    dx_dict = {\n","            '426783006': 'SNR', # Normal sinus rhythm\n","            '164889003': 'AF', # Atrial fibrillation\n","            '270492004': 'IAVB', # First-degree atrioventricular block\n","            '164909002': 'LBBB', # Left bundle branch block\n","            '713427006': 'RBBB', # Complete right bundle branch block\n","            '59118001': 'RBBB', # Right bundle branch block\n","            '284470004': 'PAC', # Premature atrial contraction\n","            '63593006': 'PAC', # Supraventricular premature beats\n","            '164884008': 'PVC', # Ventricular ectopics\n","            '429622005': 'STD', # ST-segment depression\n","            '164931005': 'STE', # ST-segment elevation\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K9Rb7XLA7qE5"},"outputs":[],"source":["#append the codes to the dictionary\n","for code in list_codes:\n","    if code not in dx_dict:\n","        # print('New code found:', code)\n","        #introduce new id sequence for new codes\n","        seq = 'Other' + str(len(dx_dict)-11+1) #original codes are 11\n","        dx_dict[code] = seq\n","# print(dx_dict)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qbJymajf7qE5"},"outputs":[],"source":["#check duplicate codes in dx_dict\n","\n","#make a list of codes\n","codes = list(dx_dict.keys())\n","#make a list of unique codes\n","unique_codes = list(set(codes))\n","#check if the length of the two lists are the same\n","if len(codes) == len(unique_codes):\n","    print('No duplicate codes')\n","else:\n","    print('Duplicate codes found')\n","    #loop through the unique codes\n","    for code in unique_codes:\n","        #count the number of times the code appears in the list of codes\n","        count = codes.count(code)\n","        #if the count is greater than 1, print the code and the count\n","        if count > 1:\n","            print(code, count)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3zSsuv7K7qE5"},"outputs":[],"source":["# store new dx_dict to file\n","dx_dict = {\n","    '426783006': 'SNR', # Normal sinus rhythm\n","    '164889003': 'AF', # Atrial fibrillation\n","    '270492004': 'IAVB', # First-degree atrioventricular block\n","    '164909002': 'LBBB', # Left bundle branch block\n","    '713427006': 'RBBB', # Complete right bundle branch block\n","    '59118001': 'RBBB', # Right bundle branch block\n","    '284470004': 'PAC', # Premature atrial contraction\n","    '63593006': 'PAC', # Supraventricular premature beats\n","    '164884008': 'PVC', # Ventricular ectopics\n","    '429622005': 'STD', # ST-segment depression\n","    '164931005': 'STE', # ST-segment elevation\n","}\n","# filename = os.path.join(data_folder, filename)\n","store_dictionary_to_file(dx_dict, file_dx_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJFNo_HS7qE5"},"outputs":[],"source":["#define function to make class labels from the dictionary\n","\n","#function to get unique values from the dictionary -> as class labels\n","def get_unique_values(dictionary):\n","    values = list(dictionary.values())\n","    unique_values = list(set(values))\n","    return unique_values\n","\n","#function to store unique values to file\n","def store_class_label_to_file(values, filename):\n","    with open(filename, 'w') as file:\n","        for value in values:\n","            file.write(value + '\\n')\n","        file.close()\n","\n","#function to load unique values from file and store in a list\n","def load_class_label_from_file(filename):\n","    class_label = []\n","    with open(filename, 'r') as file:\n","        for line in file:\n","            class_label.append(line.strip())\n","    return class_label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0xy3qTW7qE5"},"outputs":[],"source":["file_class_name = 'meta_data\\class_labels.txt' # File name to store the class labels\n","#get class labels from dictionary\n","\n","class_labels = get_unique_values(dx_dict)\n","#store class labels to file\n","store_class_label_to_file(class_labels, file_class_name)\n","\n","#load dict back to file\n","#dictionary = load_dictionary_from_file(filename)\n","#load class labels back to file\n","#class_labels = load_class_label_from_file(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MLqtpx_7qE7"},"outputs":[],"source":["#load dict back to file\n","dictionary = load_dictionary_from_file(filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY7-gbv17qE7"},"outputs":[],"source":["#Script to execute the above functions\n","\n","# 'data\\ptb-xl'\n","# 'data\\cpsc_2018'\n","# 'data\\cpsc_2018_extra'\n","# 'data\\cpsc_processed'\n","\n","\n","#python preprocess.py --data-dir 'data\\cpsc_2018_extra'\n","#python baselines.py --data-dir 'data\\cpsc_2018_extra'  --classifier 'LR'\n","#python main.py --data-dir 'data\\ptb-xl' --leads 'all' --epochs 2 --use-gpu --batch-size 200\n","#python predict.py --data-dir \"data\\cpsc_processed\" --leads 'all' --use-gpu --batch-size 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w10Gqq7J7qE7"},"outputs":[],"source":["#def function to move files .hea and .mat from one folder to another.\n","#Files name are extracted from 1st column of df\n","def move_files(df, source_folder, dest_folder):\n","    for index, row in df.iterrows():\n","        file_name = row['File']\n","        #append '.hea' and '.mat' to the file name, and move the files, one by one\n","        for ext in ['.hea', '.mat']:\n","            source_file = os.path.join(source_folder, file_name + ext)\n","            dest_file = os.path.join(dest_folder, file_name + ext)\n","            shutil.move(source_file, dest_file)\n","    print('Done moving files')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15477366,"status":"ok","timestamp":1719831334223,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"1ymPHald7qE8","outputId":"91fcae94-e68f-43d4-ba41-73d087dc9c14"},"outputs":[],"source":["# %run \"preprocess.py\" --data-dir \"data/cpsc_processed\" -- done in full\n","# %run \"preprocess.py\" --data-dir \"data/train_dataset\" -- done in full\n","\n","#run function move file and handle .hea files\n","# %run \"preprocess.py\" --data-dir \"data\\chapman_shaoxing\"\n","# %run \"preprocess.py\" --data-dir \"data\\test_dataset\"\n","# %run \"baselines.py\" --data-dir \"data\\train_dataset\" --classifier 'all'\n","# %run \"main.py\" --data-dir \"data\\cpsc_2018_extra\" --leads 'all' --epochs 1 --batch-size 200"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11430211,"status":"ok","timestamp":1719845079614,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"Kj_jtXsmEcXd","outputId":"b6b6ccd3-cd0a-41da-f503-303e6e769fcf"},"outputs":[],"source":["%run \"baselines.py\" --data-dir \"data/cpsc_processed\" --classifier 'all'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21186227,"status":"ok","timestamp":1719882929512,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"YBgZml7ZBBWg","outputId":"834cd20e-e1bf-448e-b99c-1285b68f652c"},"outputs":[],"source":["%run \"baselines.py\" --data-dir \"data/train_dataset\" --classifier 'all'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8298817,"status":"ok","timestamp":1719911814058,"user":{"displayName":"Long Dang","userId":"18213092265440286102"},"user_tz":-180},"id":"85gpnHUPALkn","outputId":"e5e0a1b9-954e-47b5-e095-53b05d03db7e"},"outputs":[],"source":["#resnet34, testset is part of trainset\n","%run \"main.py\" --data-dir \"data/cpsc_processed\" --epochs 2 --num-workers 2 --batch-size 8 --phase 'test'\n","#--epochs 4 --use-gpu --num-workers 2\n","#--phase 'train' ('test')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#resnet34 test, testset is part of train_dataset \n","%run \"main.py\" --data-dir \"data/train_dataset\" --epochs 2 --num-workers 2 --batch-size 8 --phase 'test'\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 348/348 [06:45<00:00,  1.16s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 150.4477\n","Shape of y_trues: (2782, 9)\n","Shape of y_scores: (2782, 9)\n","F1s: [0.81541409 0.93687708 0.63247863 0.76571429 0.70489039 0.67953668\n"," 0.74545455 0.42080378 0.75      ]\n","Avg F1: 0.7168\n","AUCs: [0.86476461 0.99243247 0.93949008 0.97670868 0.97025251 0.85062641\n"," 0.95459687 0.80194205 0.95711364]\n","Avg AUC: 0.9231\n"]}],"source":["#resnet34, testset is new test datase, using labels_altered.csv\n","%run \"main.py\" --data-dir \"data/cpsc_processed\" --epochs 2 --num-workers 2 --batch-size 8 --phase 'test'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training epoch 0:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2783/2783 [2:54:01<00:00,  3.75s/it]  \n"]},{"name":"stdout","output_type":"stream","text":["Loss: 492.1525\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 696/696 [13:14<00:00,  1.14s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 90.0963\n","Shape of y_trues: (5566, 9)\n","Shape of y_scores: (5566, 9)\n","F1s: [0.92325764 0.8582996  0.5963939  0.84142395 0.8256513  0.41702128\n"," 0.77697842 0.37609329 0.25806452]\n","Avg F1: 0.6526\n","Training epoch 1:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2783/2783 [2:54:19<00:00,  3.76s/it]  \n"]},{"name":"stdout","output_type":"stream","text":["Loss: 333.7152\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 696/696 [13:13<00:00,  1.14s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 75.1440\n","Shape of y_trues: (5566, 9)\n","Shape of y_scores: (5566, 9)\n","F1s: [0.93762158 0.91855584 0.67651403 0.87868852 0.85912698 0.52014652\n"," 0.80046948 0.46054054 0.27826087]\n","Avg F1: 0.7033\n","Training epoch 2:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2783/2783 [2:54:20<00:00,  3.76s/it]  \n"]},{"name":"stdout","output_type":"stream","text":["Loss: 291.0483\n","Validating...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 696/696 [13:15<00:00,  1.14s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Loss: 67.4626\n","Shape of y_trues: (5566, 9)\n","Shape of y_scores: (5566, 9)\n","F1s: [0.94713426 0.9279732  0.65426357 0.84542587 0.86359176 0.51503759\n"," 0.82978723 0.51840491 0.44705882]\n","Avg F1: 0.7276\n"]}],"source":["#resnet34 train, epochs 5, batch size 8, num workers 2\n","%run \"main.py\" --data-dir \"data/train_dataset\" --epochs 3 --num-workers 2 --batch-size 8"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
