{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "classes = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of classes in each dataset\n",
    "#count number of classes in each dataset\n",
    "def count_classes(label_file, classes):\n",
    "    df = pd.read_csv(label_file)\n",
    "    results = []\n",
    "    for label in classes:\n",
    "        count = df[label].sum()\n",
    "        results.append([label, count])\n",
    "    df = pd.DataFrame(data=results, columns=['Class', 'Count'])\n",
    "    return df\n",
    "\n",
    "#define sequence of classes, and label\n",
    "classes_8 = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'STD', 'STE']\n",
    "classes_9 = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count class distribution in ALL TRAIN dataset:\n",
    "\n",
    "#define label file location for checking string\n",
    "label_cpsc_8 = 'data/cpsc_processed/labels_8_classes.csv'\n",
    "label_cpsc_9 = 'data/cpsc_processed/labels_9_classes.csv'\n",
    "label_new_8 = 'data/op_08_classes/train_dataset/labels_8_classes.csv'\n",
    "label_new_9 = 'data/op_09_classes/train_dataset/labels_9_classes.csv'\n",
    "label_new_8_test = '/scratch/project_2010942/data/op_08_classes/test_dataset/labels_8_classes.csv'\n",
    "label_new_9_test = '/scratch/project_2010942/data/op_09_classes/test_dataset/labels_9_classes.csv'\n",
    "\n",
    "#count classes in each dataset\n",
    "df_cpsc_8 = count_classes(label_cpsc_8, classes_8)\n",
    "df_cpsc_9 = count_classes(label_cpsc_9, classes_9)\n",
    "df_new_8 = count_classes(label_new_8, classes_8)\n",
    "df_new_9 = count_classes(label_new_9, classes_9)\n",
    "df_new_8_test = count_classes(label_new_8_test, classes_8)\n",
    "df_new_9_test = count_classes(label_new_9_test, classes_9)\n",
    "\n",
    "#view results\n",
    "print('CSPC 8 classes:')\n",
    "print(df_cpsc_8.transpose())\n",
    "print('CSPC 9 classes:')\n",
    "print(df_cpsc_9.transpose())\n",
    "print('New 8 classes:')\n",
    "print(df_new_8.transpose())\n",
    "print('New 9 classes:')\n",
    "print(df_new_9.transpose())\n",
    "print('New 8 classes in TEST:')\n",
    "print(df_new_8_test.transpose())\n",
    "print('New 9 classes in TEST:')\n",
    "print(df_new_9_test.transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define folds used to split train and validation parts\n",
    "train_folds = [1, 2, 3, 5, 6, 8, 9, 10]\n",
    "validations_folds = [4, 7]\n",
    "#count sum of each class in train folds and validation folds of each dataseT\n",
    "def count_classes_folds(label_file, classes, train_folds, validations_folds):\n",
    "    df = pd.read_csv(label_file)\n",
    "    results = []\n",
    "    for label in classes:\n",
    "        count_train = df[df['fold'].isin(train_folds)][label].sum()\n",
    "        count_valid = df[df['fold'].isin(validations_folds)][label].sum()\n",
    "        results.append([label, count_train, count_valid])\n",
    "    df = pd.DataFrame(data=results, columns=['Class', 'Train', 'Validation'])\n",
    "    return df\n",
    "#count classes in each dataset\n",
    "df_cpsc_8 = count_classes_folds(label_cpsc_8, classes_8, train_folds, validations_folds)\n",
    "df_cpsc_9 = count_classes_folds(label_cpsc_9, classes_9, train_folds, validations_folds)\n",
    "df_new_8 = count_classes_folds(label_new_8, classes_8, train_folds, validations_folds)\n",
    "df_new_9 = count_classes_folds(label_new_9, classes_9, train_folds, validations_folds)\n",
    "df_new_8_test = count_classes_folds(label_new_8_test, classes_8, train_folds, validations_folds)\n",
    "df_new_9_test = count_classes_folds(label_new_9_test, classes_9, train_folds, validations_folds)\n",
    "\n",
    "#view results\n",
    "print('CSPC 8 classes:')\n",
    "print(df_cpsc_8.transpose())\n",
    "print('CSPC 9 classes:')\n",
    "print(df_cpsc_9.transpose())\n",
    "print('New 8 classes:')\n",
    "print(df_new_8.transpose())\n",
    "print('New 9 classes:')\n",
    "print(df_new_9.transpose())\n",
    "print('New 8 classes in TEST:')\n",
    "print(df_new_8_test.transpose())\n",
    "print('New 9 classes in TEST:')\n",
    "print(df_new_9_test.transpose())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir ='data\\\\op_09_classes\\\\train_dataset'\n",
    "test_label_csv = os.path.join(test_data_dir, 'labels.csv')\n",
    "# Load the test labels\n",
    "test_labels = pd.read_csv(test_label_csv)\n",
    "#show the first few rows\n",
    "print(test_labels.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count unique values '1' in the classes, sum = 0, means no '1' in the class\n",
    "for c in classes:\n",
    "    print(f'{c}: {test_labels[c].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from train_dataset\n",
    "test_labels = pd.read_csv('/workspaces/ecg-arrhythmia-model/data/train_dataset/labels.csv')\n",
    "print(test_labels.head())\n",
    "classes = ['SNR', 'AF', 'IAVB', 'LBBB', 'RBBB', 'PAC', 'PVC', 'STD', 'STE']\n",
    "#count unique values in the classes\n",
    "for c in classes:\n",
    "    print(f'{c}: {test_labels[c].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a duplcated copy of the labels.csv file in test_dataset\n",
    "import shutil\n",
    "shutil.copy('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels.csv', '/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv')\n",
    "#alter the labels_altered.csv\n",
    "test_labels = pd.read_csv('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv')\n",
    "#duplicate last row of the labels_altered.csv\n",
    "test_labels = pd.concat([test_labels,test_labels.iloc[-1]], ignore_index=True)\n",
    "#alter PVC value of the last row to 1\n",
    "test_labels.loc[test_labels.index[-1], 'PVC'] = 1\n",
    "#verify count unique values in the classes\n",
    "for c in classes:\n",
    "    print(f'{c}: {test_labels[c].sum()}')\n",
    "#save the altered labels\n",
    "test_labels.to_csv('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#load the y_trues and y_scores from file txt\n",
    "y_trues_test = np.loadtxt('/workspaces/ecg-arrhythmia-model/y_trues_test.txt')\n",
    "y_scores_test = np.loadtxt('/workspaces/ecg-arrhythmia-model/y_scores_test.txt')\n",
    "\n",
    "\n",
    "# Convert one-hot encoded y_true to class labels\n",
    "y_true_classes_test = np.argmax(y_trues_test, axis=1)\n",
    "\n",
    "# Check class distribution\n",
    "class_distribution_test = Counter(y_true_classes_test)\n",
    "print(\"Class distribution in y_true:\", class_distribution_test)\n",
    "\n",
    "# Identify problematic classes\n",
    "for class_index in range(y_trues_test.shape[1]):\n",
    "    class_true = y_trues_test[:, class_index]\n",
    "    unique_values = np.unique(class_true)\n",
    "    if len(unique_values) == 1:\n",
    "        print(f\"Class {class_index} has only one unique value: {unique_values[0]}\")\n",
    "\n",
    "#get the name of the classes index 6\n",
    "# Load the class names\n",
    "class_names = pd.read_csv('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv').columns[1:]        \n",
    "print(class_names[6])\n",
    "\n",
    "# Load few rows of the labels_altered.csv\n",
    "labels = pd.read_csv('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv')\n",
    "print(labels.head())\n",
    "\n",
    "#count unique values in the classes\n",
    "for c in classes:\n",
    "    print(f'{c}: {labels[c].sum()}')\n",
    "    \n",
    "#alter the labels_altered.csv to make the PVC class not unique\n",
    "#duplicate last row of the labels_altered.csv\n",
    "labels = pd.concat([labels, labels.iloc[-1]], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "#load the y_trues and y_scores from file txt\n",
    "y_trues_org = np.loadtxt('/workspaces/ecg-arrhythmia-model/y_trues_org.txt')\n",
    "y_scores_org = np.loadtxt('/workspaces/ecg-arrhythmia-model/y_scores_org.txt')\n",
    "\n",
    "\n",
    "# Convert one-hot encoded y_true to class labels\n",
    "y_true_classes_org = np.argmax(y_trues_org, axis=1)\n",
    "\n",
    "# Check class distribution\n",
    "class_distribution_org = Counter(y_true_classes_org)\n",
    "print(\"Class distribution in y_true:\", class_distribution_org)\n",
    "\n",
    "# Identify problematic classes\n",
    "for class_index in range(y_trues_org.shape[1]):\n",
    "    class_true = y_trues_org[:, class_index]\n",
    "    unique_values = np.unique(class_true)\n",
    "    if len(unique_values) == 1:\n",
    "        print(f\"Class {class_index} has only one unique value: {unique_values[0]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete file labels_altered.csv if it exists\n",
    "if os.path.exists('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv'):\n",
    "    os.remove('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv')\n",
    "#make new labels_altered.csv with the same content as labels.csv in test_dataset\n",
    "shutil.copy('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels.csv', '/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv')\n",
    "#update top 200 SNR records of labels_altered.csv to have PVC = 1, others = 0\n",
    "labels = pd.read_csv('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv')\n",
    "labels.loc[labels['SNR'] == 1, 'PVC'] = 1\n",
    "labels.loc[labels['SNR'] == 1, 'AF'] = 0\n",
    "labels.loc[labels['SNR'] == 1, 'IAVB'] = 0\n",
    "labels.loc[labels['SNR'] == 1, 'LBBB'] = 0\n",
    "labels.loc[labels['SNR'] == 1, 'RBBB'] = 0\n",
    "labels.loc[labels['SNR'] == 1, 'PAC'] = 0\n",
    "labels.loc[labels['SNR'] == 1, 'STD'] = 0\n",
    "labels.loc[labels['SNR'] == 1, 'STE'] = 0\n",
    "#save the altered labels\n",
    "labels.to_csv('/workspaces/ecg-arrhythmia-model/data/test_dataset/labels_altered.csv', index=False)\n",
    "\n",
    "#check distribution of the classes in the altered labels\n",
    "print(\"Label distribution in the test dataset:\")\n",
    "for c in classes:    \n",
    "    print(f'{c}: {labels[c].sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare structure, distribution of labels.csv in train_dataset and labels.csv in test_dataset\n",
    "#structure of the labels.csv in test_dataset\n",
    "print(labels_test.shape)\n",
    "#structure of the labels.csv in train_dataset\n",
    "print(labels_train[labels_train['fold'] == 9].shape)\n",
    "#count unique values in the classes\n",
    "print(\"Label distribution in the train dataset:\")\n",
    "for c in classes:    \n",
    "    print(f'{c}: {labels_train[labels_train[\"fold\"] == 9][c].sum()}')\n",
    "print(\"Label distribution in the test dataset:\")\n",
    "for c in classes:    \n",
    "    print(f'{c}: {labels_test[c].sum()}')\n",
    "#print the first few rows of the labels.csv in test_dataset\n",
    "print(labels_test.head())\n",
    "#print the first few rows of the labels.csv in train_dataset\n",
    "print(labels_train[labels_train['fold'] == 9].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
